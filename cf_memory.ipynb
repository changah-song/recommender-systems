{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory-Based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import the ratings data and save as pandas data frame\n",
    "data = [i.split(\"::\") for i in open(\"./data/ml-1m/ratings.dat\").readlines()]\n",
    "data = pd.DataFrame(data, columns=[\"user\", \"item\", \"rating\", \"timestamp\"]).drop(columns=['timestamp'])\n",
    "\n",
    "user_ids, _ = pd.factorize(data['user'])\n",
    "recipe_ids, _ = pd.factorize(data['item'])\n",
    "data['user'] = user_ids\n",
    "data['item'] = recipe_ids\n",
    "\n",
    "# create the user item matrix by pivoting the table and normalize it\n",
    "user_item_matrix = data.pivot_table(index='user', columns='item', values='rating', fill_value=2.5)\n",
    "normalized_ui_matrix = user_item_matrix.subtract(user_item_matrix.mean(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# cosine similarity matrix, user-based and item-based\n",
    "cosine_user_sim = cosine_similarity(normalized_ui_matrix)\n",
    "cosine_item_sim = cosine_similarity(normalized_ui_matrix.T)\n",
    "# pearson similarity matrix, user-based and item-based\n",
    "pearson_user_sim = normalized_ui_matrix.T.corr(method=\"pearson\")\n",
    "pearson_user_sim = pearson_user_sim.to_numpy() # convert to numpy array for compability\n",
    "pearson_item_sim = normalized_ui_matrix.corr(method=\"pearson\")\n",
    "pearson_item_sim = pearson_item_sim.to_numpy() # convert to numpy array for compability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(type, idx, top_n, sim_matrix):\n",
    "    \"\"\"\n",
    "    input: index of target user/item (int), top n number of users to use (int), similarity matrix of choice (array)\n",
    "    output: return the predicted item row for target user (user-based) or user row for target item (item-based)\n",
    "    \"\"\"\n",
    "    # filter out top n similar users/items\n",
    "    similarities = sorted(sim_matrix[idx], reverse=True)[1:top_n+1]\n",
    "    sim_dict = {}\n",
    "    # loop through all users/items and append their index and similarity value to 'sim_dict'\n",
    "    for similarity in similarities:\n",
    "        sim_dict[np.where(sim_matrix[idx] == similarity)[0][0]] = similarity\n",
    "    # create empty matrix where the prediction vector is going be saved\n",
    "    if type == 'user':\n",
    "        result = np.zeros(len(normalized_ui_matrix.columns))\n",
    "        for user in sim_dict:\n",
    "            # get scores from user item matrix using index of user\n",
    "            score = normalized_ui_matrix.loc[user]\n",
    "            # get weights of user\n",
    "            weight = sim_dict[user]\n",
    "            # weighted average for prediction (average is taken at last line)\n",
    "            result += np.dot(score, weight)\n",
    "    elif type == \"item\":\n",
    "        result = np.zeros(len(normalized_ui_matrix))\n",
    "        for item in sim_dict:\n",
    "            # get scores from user item matrix using index of item\n",
    "            score = normalized_ui_matrix[item]\n",
    "            # get weights of item\n",
    "            weight = sim_dict[item]\n",
    "            # weighted average for prediction (average is taken at last line)\n",
    "            result += np.dot(score, weight)\n",
    "    else:\n",
    "        return \"Enter valid memory-based RS type\"\n",
    "    \n",
    "    return result/sum(sim_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_ui_matrix(type, top_n, sim_matrix):\n",
    "    pred = []\n",
    "    if type == 'user':\n",
    "        for i in range(len(normalized_ui_matrix)):\n",
    "            pred.append(predict(type, i, top_n, sim_matrix))\n",
    "        pred = np.array(pred)\n",
    "        return pred\n",
    "    elif type == 'item':\n",
    "        for i in range(len(normalized_ui_matrix.loc[0])):\n",
    "            pred.append(predict(type, i, top_n, sim_matrix))\n",
    "        pred = np.array(pred)\n",
    "        return pred.T\n",
    "    else:\n",
    "        return \"Enter 'user' for user-based and 'item' for item-based CF RS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "def evaluate(type, top_n, sim_matrix):\n",
    "    pred = predicted_ui_matrix(type, top_n, sim_matrix)\n",
    "    true = np.array(normalized_ui_matrix.values.tolist())\n",
    "    # calculate RMSE, MAE, and Spearman correlation\n",
    "    rmse = np.sqrt(np.mean((pred-true)**2))\n",
    "    mae = np.mean(abs(pred-true))\n",
    "    spearman_scores = []\n",
    "    for i in range(len(true)):\n",
    "        true_rank = np.argsort(true[i])\n",
    "        predicted_rank = np.argsort(pred[i])\n",
    "        spearman_scores.append(spearmanr(true_rank, predicted_rank).correlation)\n",
    "    average_spearman_score = np.mean(spearman_scores)\n",
    "    print(\"RMSE: \", rmse, \"\\nMAE: \", mae, \"\\nSpearman: \", average_spearman_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based approach with cosine similarity\n",
      "RMSE:  0.26672632258637224 \n",
      "MAE:  0.0943938468652809 \n",
      "Spearman:  0.5938959359206174\n",
      "None \n",
      "---------\n",
      "User-based approach with pearson similarity\n",
      "RMSE:  0.2667263225863723 \n",
      "MAE:  0.09439384686528093 \n",
      "Spearman:  0.5938959349277827\n",
      "None \n",
      "---------\n",
      "Item-based approach with cosine similarity\n",
      "RMSE:  0.28283421661104957 \n",
      "MAE:  0.09080784956365832 \n",
      "Spearman:  0.23046860395364357\n",
      "None \n",
      "---------\n",
      "Item-based approach with pearson similarity\n",
      "RMSE:  0.2734087079745447 \n",
      "MAE:  0.08185400557506971 \n",
      "Spearman:  0.24259847846933547\n",
      "None \n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "print(\"User-based approach with cosine similarity\")\n",
    "print(evaluate('user', 50, cosine_user_sim), \"\\n---------\")\n",
    "\n",
    "print(\"User-based approach with pearson similarity\")\n",
    "print(evaluate('user', 50, pearson_user_sim), \"\\n---------\")\n",
    "\n",
    "print(\"Item-based approach with cosine similarity\")\n",
    "print(evaluate('item', 50, cosine_item_sim), \"\\n---------\")\n",
    "\n",
    "print(\"Item-based approach with pearson similarity\")\n",
    "print(evaluate('item', 50, pearson_item_sim), \"\\n---------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
