{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory-Based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import the ratings data and save as pandas data frame\n",
    "data = [i.split(\"::\") for i in open(\"./data/ml-1m/ratings.dat\").readlines()]\n",
    "data = pd.DataFrame(data, columns=[\"user\", \"item\", \"rating\", \"timestamp\"]).drop(columns=['timestamp'])\n",
    "\n",
    "user_ids, _ = pd.factorize(data['user'])\n",
    "recipe_ids, _ = pd.factorize(data['item'])\n",
    "data['user'] = user_ids\n",
    "data['item'] = recipe_ids\n",
    "\n",
    "# create the user item matrix by pivoting the table and normalize it\n",
    "user_item_matrix = data.pivot_table(index='user', columns='item', values='rating', fill_value=2.5)\n",
    "normalized_ui_matrix = user_item_matrix.subtract(user_item_matrix.mean(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# cosine similarity matrix, user-based and item-based\n",
    "cosine_user_sim = cosine_similarity(normalized_ui_matrix)\n",
    "cosine_item_sim = cosine_similarity(normalized_ui_matrix.T)\n",
    "# pearson similarity matrix, user-based and item-based\n",
    "pearson_user_sim = normalized_ui_matrix.T.corr(method=\"pearson\")\n",
    "pearson_user_sim = pearson_user_sim.to_numpy() # convert to numpy array for compability\n",
    "pearson_item_sim = normalized_ui_matrix.corr(method=\"pearson\")\n",
    "pearson_item_sim = pearson_item_sim.to_numpy() # convert to numpy array for compability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(type, idx, top_n, sim_matrix):\n",
    "    \"\"\"\n",
    "    input: index of target user/item (int), top n number of users to use (int), similarity matrix of choice (array)\n",
    "    output: return the predicted item row for target user (user-based) or user row for target item (item-based)\n",
    "    \"\"\"\n",
    "    # filter out top n similar users/items\n",
    "    similarities = sorted(sim_matrix[idx], reverse=True)[1:top_n+1]\n",
    "    sim_dict = {}\n",
    "    # loop through all users/items and append their index and similarity value to 'sim_dict'\n",
    "    for similarity in similarities:\n",
    "        sim_dict[np.where(sim_matrix[idx] == similarity)[0][0]] = similarity\n",
    "    # create empty matrix where the prediction vector is going be saved\n",
    "    if type == 'user':\n",
    "        result = np.zeros(len(normalized_ui_matrix.columns))\n",
    "        for user in sim_dict:\n",
    "            # get scores from user item matrix using index of user\n",
    "            score = normalized_ui_matrix.loc[user]\n",
    "            # get weights of user\n",
    "            weight = sim_dict[user]\n",
    "            # weighted average for prediction (average is taken at last line)\n",
    "            result += np.dot(score, weight)\n",
    "    elif type == \"item\":\n",
    "        result = np.zeros(len(normalized_ui_matrix))\n",
    "        for item in sim_dict:\n",
    "            # get scores from user item matrix using index of item\n",
    "            score = normalized_ui_matrix[item]\n",
    "            # get weights of item\n",
    "            weight = sim_dict[item]\n",
    "            # weighted average for prediction (average is taken at last line)\n",
    "            result += np.dot(score, weight)\n",
    "    else:\n",
    "        return \"Enter valid memory-based RS type\"\n",
    "    \n",
    "    return result/sum(sim_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_ui_matrix(type, top_n, sim_matrix):\n",
    "    pred = []\n",
    "    if type == 'user':\n",
    "        for i in range(len(normalized_ui_matrix)):\n",
    "            pred.append(predict(type, i, top_n, sim_matrix))\n",
    "        pred = np.array(pred)\n",
    "        return pred\n",
    "    elif type == 'item':\n",
    "        for i in range(len(normalized_ui_matrix.loc[0])):\n",
    "            pred.append(predict(type, i, top_n, sim_matrix))\n",
    "        pred = np.array(pred)\n",
    "        return pred.T\n",
    "    else:\n",
    "        return \"Enter 'user' for user-based and 'item' for item-based CF RS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "def evaluate(type, top_n, sim_matrix):\n",
    "    pred = predicted_ui_matrix(type, top_n, sim_matrix)\n",
    "    true = np.array(normalized_ui_matrix.values.tolist())\n",
    "    # calculate RMSE, MAE, and Spearman correlation\n",
    "    rmse = np.sqrt(np.mean((pred-true)**2))\n",
    "    mae = np.mean(abs(pred-true))\n",
    "    spearman_scores = []\n",
    "    for i in range(len(true)):\n",
    "        true_rank = np.argsort(true[i])\n",
    "        predicted_rank = np.argsort(pred[i])\n",
    "        spearman_scores.append(spearmanr(true_rank, predicted_rank).correlation)\n",
    "    average_spearman_score = np.mean(spearman_scores)\n",
    "    print(\"RMSE: \", rmse, \"\\nMAE: \", mae, \"\\nSpearman: \", average_spearman_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based approach with cosine similarity\n",
      "RMSE:  0.26672632258637224 \n",
      "MAE:  0.0943938468652809 \n",
      "Spearman:  0.5938959359206174\n",
      "None \n",
      "---------\n",
      "User-based approach with pearson similarity\n",
      "RMSE:  0.2667263225863723 \n",
      "MAE:  0.09439384686528093 \n",
      "Spearman:  0.5938959349277827\n",
      "None \n",
      "---------\n",
      "Item-based approach with cosine similarity\n",
      "RMSE:  0.28283421661104957 \n",
      "MAE:  0.09080784956365832 \n",
      "Spearman:  0.23046860395364357\n",
      "None \n",
      "---------\n",
      "Item-based approach with pearson similarity\n",
      "RMSE:  0.2734087079745447 \n",
      "MAE:  0.08185400557506971 \n",
      "Spearman:  0.24259847846933547\n",
      "None \n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "print(\"User-based approach with cosine similarity\")\n",
    "print(evaluate('user', 50, cosine_user_sim), \"\\n---------\")\n",
    "\n",
    "print(\"User-based approach with pearson similarity\")\n",
    "print(evaluate('user', 50, pearson_user_sim), \"\\n---------\")\n",
    "\n",
    "print(\"Item-based approach with cosine similarity\")\n",
    "print(evaluate('item', 50, cosine_item_sim), \"\\n---------\")\n",
    "\n",
    "print(\"Item-based approach with pearson similarity\")\n",
    "print(evaluate('item', 50, pearson_item_sim), \"\\n---------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "df = Dataset.load_from_df(data[['user', 'item', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 50 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Fold 6  Fold 7  Fold 8  Fold 9  Fold 10 Fold 11 Fold 12 Fold 13 Fold 14 Fold 15 Fold 16 Fold 17 Fold 18 Fold 19 Fold 20 Fold 21 Fold 22 Fold 23 Fold 24 Fold 25 Fold 26 Fold 27 Fold 28 Fold 29 Fold 30 Fold 31 Fold 32 Fold 33 Fold 34 Fold 35 Fold 36 Fold 37 Fold 38 Fold 39 Fold 40 Fold 41 Fold 42 Fold 43 Fold 44 Fold 45 Fold 46 Fold 47 Fold 48 Fold 49 Fold 50 Mean    Std     \n",
      "RMSE (testset)    0.8661  0.8606  0.8575  0.8515  0.8585  0.8562  0.8626  0.8599  0.8547  0.8550  0.8565  0.8626  0.8583  0.8618  0.8564  0.8638  0.8671  0.8616  0.8598  0.8573  0.8655  0.8547  0.8572  0.8624  0.8622  0.8546  0.8635  0.8533  0.8632  0.8650  0.8551  0.8565  0.8602  0.8559  0.8493  0.8648  0.8596  0.8617  0.8678  0.8515  0.8583  0.8612  0.8636  0.8659  0.8599  0.8604  0.8564  0.8648  0.8601  0.8634  0.8597  0.0043  \n",
      "MAE (testset)     0.6774  0.6733  0.6736  0.6688  0.6725  0.6701  0.6777  0.6745  0.6693  0.6705  0.6705  0.6776  0.6730  0.6737  0.6703  0.6758  0.6806  0.6749  0.6751  0.6734  0.6792  0.6720  0.6725  0.6754  0.6764  0.6713  0.6765  0.6703  0.6770  0.6763  0.6701  0.6738  0.6756  0.6721  0.6676  0.6778  0.6743  0.6757  0.6807  0.6710  0.6735  0.6777  0.6755  0.6753  0.6749  0.6738  0.6699  0.6776  0.6732  0.6782  0.6742  0.0031  \n",
      "Fit time          5.92    6.03    5.43    4.96    5.73    6.06    5.72    5.16    5.56    4.82    5.55    4.91    5.22    4.87    5.06    5.91    4.93    5.30    5.55    4.99    5.77    4.84    5.42    5.52    4.89    4.61    4.91    4.95    4.96    5.21    5.45    4.84    4.95    5.06    5.01    4.93    5.53    5.10    5.54    5.05    5.21    5.26    5.59    5.43    5.56    5.08    4.97    4.54    5.36    4.79    5.24    0.37    \n",
      "Test time         0.04    0.04    0.04    0.04    0.04    0.04    0.04    0.04    0.04    0.04    0.04    0.04    0.04    0.17    0.04    0.04    0.16    0.04    0.04    0.04    0.04    0.04    0.16    0.04    0.04    0.04    0.04    0.04    0.16    0.04    0.04    0.16    0.04    0.04    0.04    0.04    0.04    0.04    0.04    0.04    0.16    0.04    0.04    0.04    0.04    0.04    0.16    0.04    0.04    0.16    0.06    0.04    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.86609678, 0.8606188 , 0.85754558, 0.8515119 , 0.85846193,\n",
       "        0.85621684, 0.86258708, 0.85987843, 0.85466953, 0.85504155,\n",
       "        0.85652473, 0.86262736, 0.85833425, 0.86177467, 0.85643172,\n",
       "        0.86376743, 0.86707588, 0.86163477, 0.85982011, 0.85728305,\n",
       "        0.86552566, 0.85466266, 0.85716838, 0.8624132 , 0.86217122,\n",
       "        0.85462665, 0.86352042, 0.85331442, 0.86315734, 0.86504144,\n",
       "        0.85514875, 0.85648273, 0.86020175, 0.85592816, 0.84933388,\n",
       "        0.86477834, 0.85962964, 0.86171372, 0.86781709, 0.85146781,\n",
       "        0.85828187, 0.86119173, 0.86364406, 0.8659064 , 0.85985259,\n",
       "        0.8603977 , 0.8564401 , 0.86483063, 0.86010419, 0.86340547]),\n",
       " 'test_mae': array([0.6773777 , 0.67332215, 0.67360297, 0.66881312, 0.67251459,\n",
       "        0.67007171, 0.6776946 , 0.67446851, 0.66931034, 0.6704911 ,\n",
       "        0.67048474, 0.67760917, 0.67300305, 0.67365388, 0.67032957,\n",
       "        0.67576913, 0.68060997, 0.67493684, 0.67512997, 0.67335841,\n",
       "        0.6792223 , 0.67199907, 0.67245223, 0.67543773, 0.67642934,\n",
       "        0.67126331, 0.67653904, 0.67033696, 0.67701549, 0.67629926,\n",
       "        0.67010366, 0.67380915, 0.67562759, 0.67213001, 0.66760511,\n",
       "        0.67782405, 0.67433037, 0.67572987, 0.68074552, 0.67097871,\n",
       "        0.67352229, 0.67773506, 0.67549026, 0.67532378, 0.67488406,\n",
       "        0.67380302, 0.66987769, 0.67758124, 0.67319577, 0.67823755]),\n",
       " 'fit_time': (5.92182183265686,\n",
       "  6.028594017028809,\n",
       "  5.430282831192017,\n",
       "  4.96064305305481,\n",
       "  5.72682785987854,\n",
       "  6.064587116241455,\n",
       "  5.7190399169921875,\n",
       "  5.164685964584351,\n",
       "  5.559746265411377,\n",
       "  4.81526780128479,\n",
       "  5.545682191848755,\n",
       "  4.908121824264526,\n",
       "  5.220086097717285,\n",
       "  4.871572971343994,\n",
       "  5.0639238357543945,\n",
       "  5.913161039352417,\n",
       "  4.92761492729187,\n",
       "  5.301195859909058,\n",
       "  5.547386169433594,\n",
       "  4.990689992904663,\n",
       "  5.76885199546814,\n",
       "  4.835715055465698,\n",
       "  5.4188232421875,\n",
       "  5.521456956863403,\n",
       "  4.894942998886108,\n",
       "  4.61112117767334,\n",
       "  4.912353754043579,\n",
       "  4.948107004165649,\n",
       "  4.959498167037964,\n",
       "  5.206667900085449,\n",
       "  5.449376106262207,\n",
       "  4.840147018432617,\n",
       "  4.95230507850647,\n",
       "  5.064312934875488,\n",
       "  5.008217811584473,\n",
       "  4.9330220222473145,\n",
       "  5.529254913330078,\n",
       "  5.103373765945435,\n",
       "  5.544049024581909,\n",
       "  5.052172899246216,\n",
       "  5.212594985961914,\n",
       "  5.255951881408691,\n",
       "  5.58578896522522,\n",
       "  5.434078931808472,\n",
       "  5.559279203414917,\n",
       "  5.07722806930542,\n",
       "  4.972408771514893,\n",
       "  4.543906927108765,\n",
       "  5.364990949630737,\n",
       "  4.786992311477661),\n",
       " 'test_time': (0.04377102851867676,\n",
       "  0.04339408874511719,\n",
       "  0.04366302490234375,\n",
       "  0.04416799545288086,\n",
       "  0.04328274726867676,\n",
       "  0.04443693161010742,\n",
       "  0.04342770576477051,\n",
       "  0.04306197166442871,\n",
       "  0.04321098327636719,\n",
       "  0.04335308074951172,\n",
       "  0.043125152587890625,\n",
       "  0.04286694526672363,\n",
       "  0.04316878318786621,\n",
       "  0.1653907299041748,\n",
       "  0.04326510429382324,\n",
       "  0.04323601722717285,\n",
       "  0.1628248691558838,\n",
       "  0.04322099685668945,\n",
       "  0.04306793212890625,\n",
       "  0.04267287254333496,\n",
       "  0.04354405403137207,\n",
       "  0.043734073638916016,\n",
       "  0.1620957851409912,\n",
       "  0.04336214065551758,\n",
       "  0.04316592216491699,\n",
       "  0.04277920722961426,\n",
       "  0.04322624206542969,\n",
       "  0.04298281669616699,\n",
       "  0.16341280937194824,\n",
       "  0.04317307472229004,\n",
       "  0.04320192337036133,\n",
       "  0.16286492347717285,\n",
       "  0.04305624961853027,\n",
       "  0.04276609420776367,\n",
       "  0.043508291244506836,\n",
       "  0.043066978454589844,\n",
       "  0.04291391372680664,\n",
       "  0.043154239654541016,\n",
       "  0.04367685317993164,\n",
       "  0.04328322410583496,\n",
       "  0.16360902786254883,\n",
       "  0.04306912422180176,\n",
       "  0.04362010955810547,\n",
       "  0.043177127838134766,\n",
       "  0.042746782302856445,\n",
       "  0.043100833892822266,\n",
       "  0.16350817680358887,\n",
       "  0.04356718063354492,\n",
       "  0.0424351692199707,\n",
       "  0.1581559181213379)}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.model_selection import cross_validate\n",
    "from surprise import Dataset, Reader, SVD\n",
    "# pick the SVD algorithm and run it with the data and evaluation metrics\n",
    "algo = SVD()\n",
    "cross_validate(algo, df, measures=[\"RMSE\", \"MAE\"], cv=50, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8824\n",
      "MAE:  0.6938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6938167481451086"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# here we split the data into training and testing and fit the SVD model to the data\n",
    "trainset, testset = train_test_split(df, test_size=0.3)\n",
    "algo = SVD()\n",
    "algo.fit(trainset)\n",
    "prediction = algo.test(testset)\n",
    "accuracy.rmse(prediction)\n",
    "accuracy.mae(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
